{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>geometry</th>\n",
       "      <th>pressure [MPa]</th>\n",
       "      <th>mass_flux [kg/m2-s]</th>\n",
       "      <th>x_e_out [-]</th>\n",
       "      <th>D_e [mm]</th>\n",
       "      <th>D_h [mm]</th>\n",
       "      <th>length [mm]</th>\n",
       "      <th>chf_exp [MW/m2]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>tube</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>0.1754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.8</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>tube</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6049.0</td>\n",
       "      <td>-0.0416</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.3</td>\n",
       "      <td>762.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.79</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>457.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Beus</td>\n",
       "      <td>annulus</td>\n",
       "      <td>13.79</td>\n",
       "      <td>3679.0</td>\n",
       "      <td>-0.0279</td>\n",
       "      <td>5.6</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2134.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tube</td>\n",
       "      <td>13.79</td>\n",
       "      <td>686.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>457.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31639</th>\n",
       "      <td>31639</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8</td>\n",
       "      <td>591.0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31640</th>\n",
       "      <td>31640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31641</th>\n",
       "      <td>31641</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.27</td>\n",
       "      <td>658.0</td>\n",
       "      <td>-0.1224</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31642</th>\n",
       "      <td>31642</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>tube</td>\n",
       "      <td>6.89</td>\n",
       "      <td>3825.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.6</td>\n",
       "      <td>23.6</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31643</th>\n",
       "      <td>31643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tube</td>\n",
       "      <td>6.89</td>\n",
       "      <td>7568.0</td>\n",
       "      <td>0.0603</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31644 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    author geometry  pressure [MPa]  mass_flux [kg/m2-s]  \\\n",
       "0          0  Thompson     tube            7.00               3770.0   \n",
       "1          1  Thompson     tube             NaN               6049.0   \n",
       "2          2  Thompson      NaN           13.79               2034.0   \n",
       "3          3      Beus  annulus           13.79               3679.0   \n",
       "4          4       NaN     tube           13.79                686.0   \n",
       "...      ...       ...      ...             ...                  ...   \n",
       "31639  31639  Thompson      NaN             NaN               1736.0   \n",
       "31640  31640       NaN      NaN           13.79                  NaN   \n",
       "31641  31641  Thompson      NaN           18.27                658.0   \n",
       "31642  31642  Thompson     tube            6.89               3825.0   \n",
       "31643  31643       NaN     tube            6.89               7568.0   \n",
       "\n",
       "       x_e_out [-]  D_e [mm]  D_h [mm]  length [mm]  chf_exp [MW/m2]  \n",
       "0           0.1754       NaN      10.8        432.0              3.6  \n",
       "1          -0.0416      10.3      10.3        762.0              6.2  \n",
       "2           0.0335       7.7       7.7        457.0              2.5  \n",
       "3          -0.0279       5.6      15.2       2134.0              3.0  \n",
       "4              NaN      11.1      11.1        457.0              2.8  \n",
       "...            ...       ...       ...          ...              ...  \n",
       "31639       0.0886       NaN       7.8        591.0              2.3  \n",
       "31640          NaN       4.7       4.7          NaN              3.9  \n",
       "31641      -0.1224       3.0       3.0        150.0              2.3  \n",
       "31642          NaN      23.6      23.6       1972.0              3.7  \n",
       "31643       0.0603      12.8      12.8       1930.0              3.3  \n",
       "\n",
       "[31644 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"/Users/antoniojaenarias/Desktop/DATA SCIENCE/TODO/ML_KAGGLE_1/data/data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "326/326 [==============================] - 3s 6ms/step - loss: nan\n",
      "Epoch 2/50\n",
      "326/326 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 3/50\n",
      "326/326 [==============================] - 1s 4ms/step - loss: nan\n",
      "Epoch 4/50\n",
      "326/326 [==============================] - 2s 6ms/step - loss: nan\n",
      "Epoch 5/50\n",
      "182/326 [===============>..............] - ETA: 0s - loss: nan"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "\n",
    "# Supongamos que tienes tu DataFrame original en la variable \"df\"\n",
    "# Y tienes los datos incompletos en el DataFrame \"df_incomplete\"\n",
    "\n",
    "# Filtrar las filas con valores nulos en la columna \"x_e_out\"\n",
    "df_incomplete = df[df[\"x_e_out [-]\"].isnull()]\n",
    "\n",
    "# Excluir las columnas \"x_e_out\", \"author\" y \"geometry\" de los datos incompletos\n",
    "df_incomplete_excluded = df_incomplete.drop([\"x_e_out [-]\", \"author\", \"geometry\"], axis=1)\n",
    "\n",
    "# Codificar las columnas categóricas con one-hot encoding\n",
    "categorical_cols = [\"author\", \"geometry\"]\n",
    "\n",
    "# Realizar la codificación one-hot\n",
    "df_incomplete_encoded = pd.get_dummies(df_incomplete[categorical_cols])\n",
    "\n",
    "# Combinar los datos numéricos y codificados en un DataFrame completo\n",
    "df_incomplete_combined = pd.concat([df_incomplete_excluded, df_incomplete_encoded], axis=1)\n",
    "\n",
    "# Escalar los datos en el rango [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "df_incomplete_scaled = scaler.fit_transform(df_incomplete_combined)\n",
    "\n",
    "# Construcción del autoencoder\n",
    "input_dim = df_incomplete_combined.shape[1]  # Número de características de entrada\n",
    "encoding_dim = 10  # Tamaño de la representación latente\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoder = Dense(input_dim, activation='sigmoid')(encoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "# Compilación y entrenamiento del autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.fit(df_incomplete_scaled, df_incomplete_scaled, epochs=50, batch_size=32, shuffle=True)\n",
    "\n",
    "# Utilización del autoencoder para imputar valores faltantes\n",
    "# Supongamos que tienes los datos incompletos en el DataFrame \"df_incomplete\"\n",
    "\n",
    "# Excluir las columnas \"x_e_out\", \"author\" y \"geometry\" de los datos incompletos\n",
    "df_incomplete_excluded = df_incomplete.drop([\"x_e_out [-]\", \"author\", \"geometry\"], axis=1)\n",
    "\n",
    "# Realizar la codificación one-hot en los datos incompletos\n",
    "df_incomplete_encoded = pd.get_dummies(df_incomplete[categorical_cols])\n",
    "\n",
    "# Combinar los datos numéricos y codificados en un DataFrame completo\n",
    "df_incomplete_combined = pd.concat([df_incomplete_excluded, df_incomplete_encoded], axis=1)\n",
    "\n",
    "# Escalar los datos en el rango [0, 1]\n",
    "df_incomplete_scaled = scaler.transform(df_incomplete_combined)\n",
    "\n",
    "# Generar las imputaciones utilizando el autoencoder\n",
    "df_imputed_scaled = autoencoder.predict(df_incomplete_scaled)\n",
    "\n",
    "# Volver a escalar las imputaciones al rango original\n",
    "df_imputed = scaler.inverse_transform(df_imputed_scaled)\n",
    "\n",
    "# Crear un DataFrame con las imputaciones\n",
    "df_imputed_complete = pd.DataFrame(df_imputed, columns=df_incomplete_combined.columns)\n",
    "\n",
    "# Obtener las columnas categóricas originales\n",
    "df_imputed_categorical = df_incomplete[categorical_cols]\n",
    "\n",
    "# Codificar las columnas categóricas nuevamente\n",
    "df_imputed_encoded = pd.get_dummies(df_imputed_categorical)\n",
    "\n",
    "# Combinar las columnas numéricas y las columnas categóricas codificadas\n",
    "df_imputed_final = pd.concat([df_imputed_complete.drop(categorical_cols, axis=1), df_imputed_encoded], axis=1)\n",
    "\n",
    "# Concatenar las filas imputadas con las filas originales completas\n",
    "df_complete = pd.concat([df.dropna(subset=[\"x_e_out\"]), df_imputed_final])\n",
    "\n",
    "# Dividir el DataFrame completo en conjuntos de entrenamiento y prueba\n",
    "train_indices, test_indices = train_test_split(df_complete.index, test_size=0.2, random_state=42)\n",
    "df_train = df_complete.loc[train_indices]\n",
    "df_test = df_complete.loc[test_indices]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
